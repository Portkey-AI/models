{
  "default": {
    "messages": {
      "options": [
        "system",
        "user",
        "assistant"
      ]
    },
    "params": [
      {
        "defaultValue": 256,
        "key": "max_tokens",
        "maxValue": 4096,
        "minValue": 1
      },
      {
        "defaultValue": 0.7,
        "key": "temperature",
        "maxValue": 2,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_p",
        "maxValue": 1,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "n",
        "maxValue": 10,
        "minValue": 1
      },
      {
        "defaultValue": null,
        "key": "stop",
        "skipValues": [
          null,
          []
        ],
        "type": "array-of-strings"
      },
      {
        "defaultValue": true,
        "key": "stream",
        "type": "boolean"
      },
      {
        "defaultValue": null,
        "key": "tool_choice",
        "options": [
          {
            "name": "None",
            "value": "none"
          },
          {
            "name": "Auto",
            "value": "auto"
          },
          {
            "name": "Required",
            "value": "required"
          },
          {
            "name": "Custom",
            "schema": {
              "type": "json"
            },
            "value": "custom"
          }
        ],
        "rule": {
          "default": {
            "condition": "tools",
            "else": null,
            "then": "auto"
          }
        },
        "skipValues": [
          null,
          []
        ],
        "type": "non-view-manage-data"
      }
    ],
    "type": {
      "primary": "chat",
      "supported": []
    }
  },
  "description": "",
  "models": {
    "accounts/fireworks/models/bleat-adapter": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/chinese-llama-2-lora-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/codegemma-2b": {
      "capabilities": [
        "code"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/dbrx-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/deepseek-r1": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/deepseek-v3": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/firefunction-v1": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/firellava-13b": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/gemma-7b-it": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/gpt-oss-120b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "accounts/fireworks/models/gpt-oss-20b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "accounts/fireworks/models/hermes-2-pro-mistral-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-2-13b-fp16-french": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama-2-13b-guanaco-peft": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama-v2-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama-v2-13b-chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v2-70b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v2-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama-v2-7b-chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3-70b-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3-70b-instruct-hf": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3-8b-hf": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama-v3-8b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p1-405b-instruct": {
      "max_output_tokens": 4096,
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p1-70b-instruct": {
      "max_output_tokens": 4096,
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p1-8b-instruct": {
      "max_output_tokens": 4096,
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p2-1b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p2-3b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama-v3p3-70b-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama2-7b-summarize": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/llama4-maverick-instruct-basic": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 16384,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 16384,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llama4-scout-instruct-basic": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 16384,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 16384,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/llava-yi-34b": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mistral-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/mistral-7b-instruct-4k": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mistral-7b-instruct-v0p2": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mistral-7b-instruct-v3": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mixtral-8x22b-hf": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/mixtral-8x22b-instruct": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mixtral-8x22b-instruct-hf": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mixtral-8x7b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/mixtral-8x7b-instruct": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/mythomax-l2-13b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo-fp8": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/phi-3-vision-128k-instruct": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/qwen1p5-72b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/qwen2-72b-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/fireworks/models/starcoder-16b": {
      "capabilities": [
        "code"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/starcoder-7b": {
      "capabilities": [
        "code"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/traditional-chinese-qlora-llama2": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "text"
    },
    "accounts/fireworks/models/yi-34b-200k-capybara": {
      "max_output_tokens": 200000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 200000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/stability/models/japanese-stablelm-instruct-beta-70b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/stability/models/japanese-stablelm-instruct-gamma-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/stability/models/stablelm-2-zephyr-2b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "accounts/stability/models/stablelm-zephyr-3b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    }
  },
  "provider": "fireworks",
  "provider_name": "fireworks"
}
