{
  "default": {
    "messages": {
      "options": [
        "system",
        "user",
        "assistant"
      ]
    },
    "params": [
      {
        "defaultValue": 256,
        "key": "max_tokens",
        "maxValue": 32768,
        "minValue": 1
      },
      {
        "defaultValue": 0.7,
        "key": "temperature",
        "maxValue": 2,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_p",
        "maxValue": 1,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_k",
        "maxValue": 2048,
        "minValue": 0
      },
      {
        "defaultValue": 0,
        "key": "frequency_penalty",
        "maxValue": 2,
        "minValue": -2
      },
      {
        "defaultValue": null,
        "key": "stop",
        "skipValues": [
          null,
          []
        ],
        "type": "array-of-strings"
      },
      {
        "defaultValue": true,
        "key": "stream",
        "type": "boolean"
      },
      {
        "defaultValue": null,
        "key": "tool_choice",
        "options": [
          {
            "name": "None",
            "value": "none"
          },
          {
            "name": "Auto",
            "value": "auto"
          },
          {
            "name": "Required",
            "value": "required"
          },
          {
            "name": "Custom",
            "schema": {
              "type": "json"
            },
            "value": "custom"
          }
        ],
        "rule": {
          "default": {
            "condition": "tools",
            "else": null,
            "then": "auto"
          }
        },
        "skipValues": [
          null,
          []
        ],
        "type": "non-view-manage-data"
      }
    ],
    "pricing": {
      "calculate": {
        "request": {
          "operands": [
            {
              "value": "input_tokens"
            },
            {
              "value": "rates.request_token"
            }
          ],
          "operation": "multiply"
        },
        "response": {
          "operands": [
            {
              "value": "output_tokens"
            },
            {
              "value": "rates.response_token"
            }
          ],
          "operation": "multiply"
        }
      },
      "currency": "USD"
    },
    "type": {
      "primary": "chat",
      "supported": []
    }
  },
  "description": "",
  "models": {
    "Austism/chronos-hermes-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "BAAI/bge-base-en-v1.5": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "embedding"
    },
    "BAAI/bge-large-en-v1.5": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.016
      },
      "type": "embedding"
    },
    "ByteDance-Seed/SeedEdit": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 3
            }
          }
        }
      },
      "type": "chat"
    },
    "ByteDance-Seed/Seedream-3.0": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 1.8
            }
          }
        }
      },
      "type": "image"
    },
    "ByteDance-Seed/Seedream-4.0": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 3
            }
          }
        }
      },
      "type": "image"
    },
    "DiscoResearch/DiscoLM-mixtral-8x7b-v2": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.6,
        "output": 0.6
      },
      "type": "chat"
    },
    "EleutherAI/llemma_7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "Gryphe/MythoMax-L2-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "HiDream-ai/HiDream-I1-Dev": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.45
            }
          }
        }
      },
      "type": "chat"
    },
    "HiDream-ai/HiDream-I1-Fast": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.32
            }
          }
        }
      },
      "type": "chat"
    },
    "HiDream-ai/HiDream-I1-Full": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.9
            }
          }
        }
      },
      "type": "chat"
    },
    "Lykon/DreamShaper": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.06
            }
          }
        }
      },
      "type": "chat"
    },
    "Meta-Llama/Llama-Guard-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "Nexusflow/NexusRaven-V2-13B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "NousResearch/Nous-Capybara-7B-V1p9": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "NousResearch/Nous-Hermes-2-Yi-34B": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "chat"
    },
    "NousResearch/Nous-Hermes-Llama2-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "NousResearch/Nous-Hermes-Llama2-70b": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "chat"
    },
    "NousResearch/Nous-Hermes-llama-2-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "NumbersStation/nsql-llama-2-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "Open-Orca/Mistral-7B-OpenOrca": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "Phind/Phind-CodeLlama-34B-Python-v1": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "Phind/Phind-CodeLlama-34B-v2": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "Qwen/QwQ-32B": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.2,
        "output": 1.2
      },
      "type": "chat"
    },
    "Qwen/Qwen-Image": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.58
            }
          }
        }
      },
      "type": "chat"
    },
    "Qwen/Qwen-Image-Edit": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.32
            }
          }
        }
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-72B-Instruct-Turbo": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.2,
        "output": 1.2
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-7B-Instruct-Turbo": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-Coder-32B-Instruct": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "Qwen/Qwen2.5-VL-72B-Instruct": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.95,
        "output": 8
      },
      "type": "chat"
    },
    "Qwen/Qwen3-235B-A22B-Instruct-2507-tput": {
      "max_output_tokens": 262144,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.6
      },
      "type": "chat"
    },
    "Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "max_output_tokens": 262144,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.65,
        "output": 3
      },
      "type": "chat"
    },
    "Qwen/Qwen3-235B-A22B-fp8-tput": {
      "max_output_tokens": 40960,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.6
      },
      "type": "chat"
    },
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "max_output_tokens": 256000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 256000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 2,
        "output": 2
      },
      "type": "chat"
    },
    "Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "max_output_tokens": 262144,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "max_output_tokens": 262144,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "RunDiffusion/Juggernaut-pro-flux": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.49
            }
          }
        }
      },
      "type": "image"
    },
    "Rundiffusion/Juggernaut-Lightning-Flux": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.17
            }
          }
        }
      },
      "type": "image"
    },
    "WhereIsAI/UAE-Large-V1": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.016
      },
      "type": "chat"
    },
    "WizardLM/WizardCoder-15B-V1.0": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "text"
    },
    "WizardLM/WizardCoder-Python-34B-V1.0": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "WizardLM/WizardLM-13B-V1.2": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "WizardLM/WizardLM-70B-V1.0": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "arcee-ai/arcee-blitz": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "arcee-ai/caller": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "arcee-ai/coder-large": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.5,
        "output": 0.8
      },
      "type": "chat"
    },
    "arcee-ai/maestro-reasoning": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 3.3
      },
      "type": "chat"
    },
    "arcee-ai/virtuoso-large": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.75,
        "output": 1.2
      },
      "type": "chat"
    },
    "arcee-ai/virtuoso-medium-v2": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "arcee_ai/arcee-spotlight": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "bert-base-uncased": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "chat"
    },
    "black-forest-labs/FLUX.1-Canny-pro": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 5
            }
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-dev": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 2.5
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-kontext-dev": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 2.5
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-kontext-max": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 8
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-kontext-pro": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 4
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-krea-dev": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 2.5
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-pro": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 2800
          },
          "megapixels": {
            "price": 5
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-schnell": {
      "disablePlayground": true,
      "pricing": {
        "additional_units": {
          "default_steps": {
            "price": 400
          },
          "megapixels": {
            "price": 0.27
          }
        }
      },
      "type": "image"
    },
    "black-forest-labs/FLUX.1-schnell-Free": {
      "disablePlayground": true,
      "pricing": null,
      "type": "image"
    },
    "black-forest-labs/FLUX.1.1-pro": {
      "disablePlayground": true,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 4
            }
          }
        }
      },
      "type": "image"
    },
    "cartesia/sonic": {
      "disablePlayground": true,
      "pricing": null,
      "type": "audio"
    },
    "cartesia/sonic-2": {
      "disablePlayground": true,
      "pricing": null,
      "type": "audio"
    },
    "databricks/dbrx-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.2,
        "output": 1.2
      },
      "type": "chat"
    },
    "deepcogito/cogito-v2-preview-deepseek-671b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.25,
        "output": 1.25
      },
      "type": "chat"
    },
    "deepcogito/cogito-v2-preview-llama-109B-MoE": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.59
      },
      "type": "chat"
    },
    "deepcogito/cogito-v2-preview-llama-405B": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 3.5,
        "output": 3.5
      },
      "type": "chat"
    },
    "deepcogito/cogito-v2-preview-llama-70B": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.88,
        "output": 0.88
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 3,
        "output": 7
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1-0528-tput": {
      "max_output_tokens": 163839,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 163839,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.55,
        "output": 2.19
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "max_output_tokens": 131072,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 2,
        "output": 2
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "max_output_tokens": 131072,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.18
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.25,
        "output": 1.25
      },
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3-0324": {
      "max_output_tokens": 163839,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 163839,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "deepseek-ai/DeepSeek-V3.1": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.6,
        "output": 1.7
      },
      "type": "chat"
    },
    "deepseek-ai/deepseek-llm-67b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "garage-bAInd/Platypus2-70B-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "google/flash-image-2.5": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.39
            }
          }
        }
      },
      "type": "chat"
    },
    "google/gemma-2b-it": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "google/gemma-3n-E4B-it": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.02,
        "output": 0.04
      },
      "type": "chat"
    },
    "google/imagen-4.0-fast": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 2
            }
          }
        }
      },
      "type": "image"
    },
    "google/imagen-4.0-preview": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 4
            }
          }
        }
      },
      "type": "image"
    },
    "google/imagen-4.0-ultra": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 6
            }
          }
        }
      },
      "type": "image"
    },
    "huggyllama/llama-65b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "ideogram/ideogram-3.0": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 6
            }
          }
        }
      },
      "type": "chat"
    },
    "lmsys/vicuna-13b-v1.5": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "lmsys/vicuna-13b-v1.5-16k": {
      "max_output_tokens": 16384,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 16384,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "lmsys/vicuna-7b-v1.5": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "chat"
    },
    "marin-community/marin-8b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.18
      },
      "type": "chat"
    },
    "meta-llama/Llama-2-7b-chat-hf": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "meta-llama/Llama-3-70b-chat-hf": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "meta-llama/Llama-3-8b-chat-hf": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.18
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.06,
        "output": 0.06
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.2,
        "output": 1.2
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.88,
        "output": 0.88
      },
      "type": "chat"
    },
    "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
      "max_output_tokens": 131072,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 1048576,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 1048576,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.27,
        "output": 0.85
      },
      "type": "chat"
    },
    "meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 1048576,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 1048576,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.59
      },
      "type": "chat"
    },
    "meta-llama/Llama-Vision-Free": {
      "capabilities": [
        "image"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.1,
        "output": 0.1
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 3.5,
        "output": 3.5
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Reference": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.88,
        "output": 0.88
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-70B-Reference": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.18,
        "output": 0.18
      },
      "type": "chat"
    },
    "meta-llama/Meta-Llama-3.1-8B-Reference": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "mistralai/Magistral-Small-2506": {
      "max_output_tokens": 40960,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "mistralai/Mistral-7B-Instruct-v0.1": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "mistralai/Mistral-7B-Instruct-v0.2": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "mistralai/Mistral-7B-Instruct-v0.3": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "mistralai/Mistral-7B-v0.1": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "text"
    },
    "mistralai/Mistral-Small-24B-Instruct-2501": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x22B": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1.2,
        "output": 1.2
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x7B-Instruct-v0.1": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.6,
        "output": 0.6
      },
      "type": "chat"
    },
    "mistralai/Mixtral-8x7B-v0.1": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.6,
        "output": 0.6
      },
      "type": "chat"
    },
    "moonshot-ai/kimi-k2-instruct": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 1,
        "output": 3
      },
      "type": "chat"
    },
    "moonshot-ai/kimi-k2-instruct-0905": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 1,
        "output": 3
      },
      "type": "chat"
    },
    "moonshot-ai/kimi-k2-thinking": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 1.2,
        "output": 4
      },
      "type": "chat"
    },
    "moonshotai/Kimi-K2-Instruct": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 3
      },
      "type": "chat"
    },
    "moonshotai/Kimi-K2-Instruct-0905": {
      "max_output_tokens": 262144,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 262144,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 3
      },
      "type": "chat"
    },
    "moonshotai/Kimi-K2-Thinking": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 1.2,
        "output": 4
      },
      "type": "chat"
    },
    "openai/gpt-oss-120b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.15,
        "output": 0.6
      },
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "openai/gpt-oss-20b": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.05,
        "output": 0.2
      },
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "openai/whisper-large-v3": {
      "disablePlayground": true,
      "pricing": null,
      "type": "audio"
    },
    "openchat/openchat-3.5-1210": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "sentence-transformers/msmarco-bert-base-dot-v5": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "chat"
    },
    "stabilityai/stable-diffusion-3-medium": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.19
            }
          }
        }
      },
      "type": "image"
    },
    "stabilityai/stable-diffusion-xl-base-1.0": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "image": {
          "default": {
            "default": {
              "price": 0.19
            }
          }
        }
      },
      "type": "image"
    },
    "teknium/OpenHermes-2-Mistral-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "teknium/OpenHermes-2p5-Mistral-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.22,
        "output": 0.22
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-13b-Instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.22,
        "output": 0.22
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-13b-Python": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.22,
        "output": 0.22
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-34b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-34b-Instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-34b-Python": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-7b-Instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/CodeLlama-7b-Python": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/GPT-JT-6B-v1": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/GPT-JT-Moderation-6B": {
      "disablePlayground": true,
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "moderation"
    },
    "togethercomputer/GPT-NeoXT-Chat-Base-20B": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "togethercomputer/LLaMA-2-7B-32K": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/Llama-2-7B-32K-Instruct": {
      "max_output_tokens": 32768,
      "pricing": null,
      "type": "chat"
    },
    "togethercomputer/Pythia-Chat-Base-7B-v0.16": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/Qwen-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/Qwen-7B-Chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-7B-Base": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-7B-Chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-7B-Instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-Base-3B-v1": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.1,
        "output": 0.1
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-Chat-3B-v1": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.1,
        "output": 0.1
      },
      "type": "chat"
    },
    "togethercomputer/RedPajama-INCITE-Instruct-3B-v1": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.1,
        "output": 0.1
      },
      "type": "chat"
    },
    "togethercomputer/StripedHyena-Hessian-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/StripedHyena-Nous-7B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/alpaca-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/falcon-40b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "togethercomputer/falcon-40b-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "togethercomputer/falcon-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/falcon-7b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-13b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.22,
        "output": 0.22
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-13b-chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.22,
        "output": 0.22
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-70b": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-70b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-7b": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/llama-2-7b-chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "togethercomputer/m2-bert-80M-2k-retrieval": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "chat"
    },
    "togethercomputer/m2-bert-80M-32k-retrieval": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "chat"
    },
    "togethercomputer/m2-bert-80M-8k-retrieval": {
      "disablePlayground": true,
      "max_output_tokens": 32768,
      "pricing": {
        "input": 0.008
      },
      "type": "chat"
    },
    "upstage/SOLAR-0-70b-16bit": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.9,
        "output": 0.9
      },
      "type": "chat"
    },
    "upstage/SOLAR-10.7B-Instruct-v1.0": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.3,
        "output": 0.3
      },
      "type": "chat"
    },
    "zai-org/GLM-4.5-Air-FP8": {
      "max_output_tokens": 131072,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 1.1
      },
      "type": "chat"
    },
    "zero-one-ai/Yi-34B": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "zero-one-ai/Yi-34B-Chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "zero-one-ai/Yi-6B": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        }
      ],
      "pricing": {
        "input": 0.14,
        "output": 0.14
      },
      "type": "chat"
    }
  },
  "provider": "together-ai",
  "provider_name": "together-ai"
}
