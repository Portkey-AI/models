{
  "default": {
    "messages": {
      "options": [
        "system",
        "user",
        "assistant"
      ]
    },
    "params": [
      {
        "defaultValue": 256,
        "key": "max_tokens",
        "maxValue": 32768,
        "minValue": 1
      },
      {
        "defaultValue": 0.7,
        "key": "temperature",
        "maxValue": 2,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_p",
        "maxValue": 1,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_k",
        "maxValue": 2048,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "n",
        "maxValue": 10,
        "minValue": 1
      },
      {
        "defaultValue": 0,
        "key": "frequency_penalty",
        "maxValue": 2,
        "minValue": -2
      },
      {
        "defaultValue": 0,
        "key": "presence_penalty",
        "maxValue": 2,
        "minValue": -2
      },
      {
        "defaultValue": null,
        "key": "stop",
        "skipValues": [
          null,
          []
        ],
        "type": "array-of-strings"
      },
      {
        "defaultValue": true,
        "key": "stream",
        "type": "boolean"
      }
    ],
    "pricing": {
      "calculate": {
        "request": {
          "operands": [
            {
              "value": "input_tokens"
            },
            {
              "value": "rates.request_token"
            }
          ],
          "operation": "multiply"
        },
        "response": {
          "operands": [
            {
              "value": "output_tokens"
            },
            {
              "value": "rates.response_token"
            }
          ],
          "operation": "multiply"
        }
      },
      "currency": "USD"
    },
    "type": {
      "primary": "chat",
      "supported": []
    }
  },
  "description": "",
  "models": {
    "codellama-34b-instruct": {
      "capabilities": [
        "code"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.8,
        "output": 0.8
      },
      "type": "chat"
    },
    "codellama-70b-instruct": {
      "capabilities": [
        "code"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-2-70b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3-70b-instruct": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3-8b-instruct": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "llama-3-sonar-large-32k-chat": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3-sonar-large-32k-online": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3-sonar-small-32k-chat": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "llama-3-sonar-small-32k-online": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "llama-3.1-70b-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3.1-8b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3.1-sonar-huge-128k-online": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 5,
        "output": 5
      },
      "type": "chat"
    },
    "llama-3.1-sonar-large-128k-chat": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3.1-sonar-large-128k-online": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "llama-3.1-sonar-small-128k-chat": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "llama-3.1-sonar-small-128k-online": {
      "max_output_tokens": 128000,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 128000,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "mistral-7b-instruct": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "mixtral-8x7b-instruct": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.6,
        "output": 0.6
      },
      "type": "chat"
    },
    "pplx-70b-chat": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "pplx-70b-online": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "output": 2.8
      },
      "type": "chat"
    },
    "pplx-7b-chat": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "pplx-7b-online": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_k",
          "maxValue": 2048,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "n",
          "maxValue": 10,
          "minValue": 1
        },
        {
          "defaultValue": 0,
          "key": "frequency_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": 0,
          "key": "presence_penalty",
          "maxValue": 2,
          "minValue": -2
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "output": 0.28
      },
      "type": "chat"
    },
    "r1-1776": {
      "max_output_tokens": 32768,
      "pricing": {
        "input": 2,
        "output": 8
      },
      "type": "chat"
    },
    "sonar": {
      "max_output_tokens": 32768,
      "pricing": {
        "additional_units": {
          "web_search_high_context": {
            "price": 120
          },
          "web_search_low_context": {
            "price": 50
          },
          "web_search_medium_context": {
            "price": 80
          }
        },
        "input": 1,
        "output": 1
      },
      "type": "chat"
    },
    "sonar-deep-research": {
      "max_output_tokens": 32768,
      "pricing": {
        "additional_units": {
          "web_search": {
            "price": 50
          }
        },
        "input": 2,
        "output": 8
      },
      "type": "chat"
    },
    "sonar-pro": {
      "max_output_tokens": 32768,
      "pricing": {
        "additional_units": {
          "web_search_high_context": {
            "price": 140
          },
          "web_search_low_context": {
            "price": 60
          },
          "web_search_medium_context": {
            "price": 100
          }
        },
        "input": 3,
        "output": 15
      },
      "type": "chat"
    },
    "sonar-reasoning": {
      "max_output_tokens": 32768,
      "pricing": {
        "additional_units": {
          "web_search_high_context": {
            "price": 120
          },
          "web_search_low_context": {
            "price": 50
          },
          "web_search_medium_context": {
            "price": 80
          }
        },
        "input": 1,
        "output": 5
      },
      "type": "chat"
    },
    "sonar-reasoning-pro": {
      "max_output_tokens": 32768,
      "pricing": {
        "additional_units": {
          "web_search_high_context": {
            "price": 140
          },
          "web_search_low_context": {
            "price": 60
          },
          "web_search_medium_context": {
            "price": 100
          }
        },
        "input": 2,
        "output": 8
      },
      "type": "chat"
    }
  },
  "provider": "perplexity-ai",
  "provider_name": "perplexity-ai"
}
