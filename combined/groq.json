{
  "default": {
    "messages": {
      "options": [
        "system",
        "user",
        "assistant"
      ]
    },
    "params": [
      {
        "defaultValue": 256,
        "key": "max_tokens",
        "maxValue": 4096,
        "minValue": 1
      },
      {
        "defaultValue": 0.7,
        "key": "temperature",
        "maxValue": 2,
        "minValue": 0
      },
      {
        "defaultValue": 1,
        "key": "top_p",
        "maxValue": 1,
        "minValue": 0
      },
      {
        "defaultValue": null,
        "key": "stop",
        "skipValues": [
          null,
          []
        ],
        "type": "array-of-strings"
      },
      {
        "defaultValue": true,
        "key": "stream",
        "type": "boolean"
      }
    ],
    "pricing": {
      "calculate": {
        "request": {
          "operands": [
            {
              "value": "input_tokens"
            },
            {
              "value": "rates.request_token"
            }
          ],
          "operation": "multiply"
        },
        "response": {
          "operands": [
            {
              "value": "output_tokens"
            },
            {
              "value": "rates.response_token"
            }
          ],
          "operation": "multiply"
        }
      },
      "currency": "USD"
    },
    "type": {
      "primary": "chat",
      "supported": []
    }
  },
  "description": "",
  "models": {
    "compound-beta": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "compound-beta-mini": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "deepseek-r1-distill-llama-70b": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 131072,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 131072,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.75,
        "output": 0.99
      },
      "type": "chat"
    },
    "deepseek-r1-distill-qwen-32b": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "gemma-7b-it": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.1,
        "output": 0.1
      },
      "type": "chat"
    },
    "gemma2-9b-it": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "llama-3.1-70b-versatile": {
      "max_output_tokens": 4096,
      "pricing": {
        "input": 0.59,
        "output": 0.79
      },
      "type": "chat"
    },
    "llama-3.1-8b-instant": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.05,
        "output": 0.08
      },
      "type": "chat"
    },
    "llama-3.2-11b-vision-preview": {
      "capabilities": [
        "image",
        "tools"
      ],
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "llama-3.2-1b-preview": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "llama-3.2-3b-preview": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "llama-3.2-90b-vision-preview": {
      "capabilities": [
        "image",
        "tools"
      ],
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "llama-3.3-70b-specdec": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "llama-3.3-70b-versatile": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.59,
        "output": 0.79
      },
      "type": "chat"
    },
    "llama-guard-3-8b": {
      "max_output_tokens": 4096,
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "moderation"
    },
    "llama2-70b-4096": {
      "max_output_tokens": 4096,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 4096,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.7,
        "output": 0.8
      },
      "type": "chat"
    },
    "llama3-70b-8192": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.59,
        "output": 0.79
      },
      "type": "chat"
    },
    "llama3-8b-8192": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.05,
        "output": 0.08
      },
      "type": "chat"
    },
    "llama3-groq-70b-8192-tool-use-preview": {
      "max_output_tokens": 4096,
      "pricing": {
        "input": 0.89,
        "output": 0.89
      },
      "type": "chat"
    },
    "llama3-groq-8b-8192-tool-use-preview": {
      "max_output_tokens": 4096,
      "pricing": {
        "input": 0.19,
        "output": 0.19
      },
      "type": "chat"
    },
    "meta-llama/llama-4-maverick-17b-128e-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.6
      },
      "type": "chat"
    },
    "meta-llama/llama-4-scout-17b-16e-instruct": {
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.11,
        "output": 0.34
      },
      "type": "chat"
    },
    "meta-llama/llama-guard-4-12b": {
      "max_output_tokens": 1024,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 1024,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.2,
        "output": 0.2
      },
      "type": "chat"
    },
    "meta-llama/llama-prompt-guard-2-22m": {
      "max_output_tokens": 512,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 512,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "meta-llama/llama-prompt-guard-2-86m": {
      "max_output_tokens": 512,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 512,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "mixtral-8x7b-32768": {
      "capabilities": [
        "tools"
      ],
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.24,
        "output": 0.24
      },
      "type": "chat"
    },
    "moonshotai/kimi-k2-instruct": {
      "max_output_tokens": 16384,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 16384,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "chat"
    },
    "moonshotai/kimi-k2-instruct-0905": {
      "max_output_tokens": 4096,
      "pricing": {
        "cache_read": 0.5,
        "input": 1,
        "output": 3
      },
      "type": "chat"
    },
    "openai/gpt-oss-120b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.15,
        "output": 0.6
      },
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "openai/gpt-oss-20b": {
      "max_output_tokens": 32768,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 32768,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        },
        {
          "defaultValue": null,
          "key": "tool_choice",
          "options": [
            {
              "name": "None",
              "value": "none"
            },
            {
              "name": "Auto",
              "value": "auto"
            },
            {
              "name": "Required",
              "value": "required"
            },
            {
              "name": "Custom",
              "schema": {
                "type": "json"
              },
              "value": "custom"
            }
          ],
          "rule": {
            "default": {
              "condition": "tools",
              "else": null,
              "then": "auto"
            }
          },
          "skipValues": [
            null,
            []
          ],
          "type": "non-view-manage-data"
        },
        {
          "defaultValue": null,
          "key": "response_format",
          "options": [
            {
              "name": "Text",
              "value": null
            },
            {
              "name": "JSON Object",
              "schema": {
                "properties": {
                  "type": {
                    "type": "string",
                    "value": "json_object"
                  }
                },
                "type": "object"
              },
              "value": "json_object"
            },
            {
              "name": "JSON Schema",
              "params": {
                "defaultValue": null,
                "key": "json_schema",
                "skipValues": [
                  null
                ],
                "type": "json"
              },
              "schema": {
                "properties": {
                  "json_schema": {
                    "type": "object"
                  },
                  "type": {
                    "type": "string",
                    "value": "json_schema"
                  }
                },
                "type": "object"
              },
              "value": "json_schema"
            }
          ],
          "skipValues": [
            null
          ],
          "type": "string"
        }
      ],
      "pricing": {
        "input": 0.075,
        "output": 0.3
      },
      "removeParams": [
        "stream"
      ],
      "type": "chat"
    },
    "openai/gpt-oss-safeguard-20b": {
      "disablePlayground": true,
      "max_output_tokens": 4096,
      "pricing": {
        "input": 0.075,
        "output": 0.3
      },
      "type": "moderation"
    },
    "playai-tts": {
      "disablePlayground": true,
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "audio"
    },
    "playai-tts-arabic": {
      "disablePlayground": true,
      "max_output_tokens": 8192,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 8192,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": null,
      "type": "audio"
    },
    "qwen/qwen3-32b": {
      "max_output_tokens": 40960,
      "params": [
        {
          "defaultValue": 256,
          "key": "max_tokens",
          "maxValue": 40960,
          "minValue": 1
        },
        {
          "defaultValue": 0.7,
          "key": "temperature",
          "maxValue": 2,
          "minValue": 0
        },
        {
          "defaultValue": 1,
          "key": "top_p",
          "maxValue": 1,
          "minValue": 0
        },
        {
          "defaultValue": null,
          "key": "stop",
          "skipValues": [
            null,
            []
          ],
          "type": "array-of-strings"
        },
        {
          "defaultValue": true,
          "key": "stream",
          "type": "boolean"
        }
      ],
      "pricing": {
        "input": 0.29,
        "output": 0.59
      },
      "type": "chat"
    },
    "whisper-large-v3": {
      "disablePlayground": true,
      "pricing": null,
      "type": "audio"
    },
    "whisper-large-v3-turbo": {
      "disablePlayground": true,
      "pricing": null,
      "type": "audio"
    }
  },
  "provider": "groq",
  "provider_name": "groq"
}
